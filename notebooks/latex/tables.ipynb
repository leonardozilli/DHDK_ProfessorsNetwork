{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lattice_reference'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mguen\\Desktop\\DHDK_ProfessorsNetwork\\notebooks\\latex\\tables.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mguen/Desktop/DHDK_ProfessorsNetwork/notebooks/latex/tables.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmath\u001b[39;00m \u001b[39mimport\u001b[39;00m log\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mguen/Desktop/DHDK_ProfessorsNetwork/notebooks/latex/tables.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstatistics\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mst\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mguen/Desktop/DHDK_ProfessorsNetwork/notebooks/latex/tables.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlattice_reference\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mguen/Desktop/DHDK_ProfessorsNetwork/notebooks/latex/tables.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjoblib\u001b[39;00m \u001b[39mimport\u001b[39;00m Parallel, delayed\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mguen/Desktop/DHDK_ProfessorsNetwork/notebooks/latex/tables.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lattice_reference'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import log\n",
    "import statistics as st\n",
    "from lattice_reference import *\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    " \n",
    "threads = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Number of nodes and edges for each graph.}\n",
      "\\label{tab:graph_stats}\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "Graph &  Number of Nodes &  Number of Edges \\\\\n",
      "\\midrule\n",
      " DHDK &              398 &             1889 \\\\\n",
      "   CS &              493 &             1999 \\\\\n",
      "   IT &              304 &             1523 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mguen\\AppData\\Local\\Temp\\ipykernel_8916\\565526070.py:13: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df.to_latex(index=False, caption=\"Number of nodes and edges for each graph.\", label=\"tab:graph_stats\")\n"
     ]
    }
   ],
   "source": [
    "G1 = nx.read_gml(\"../../data/dhdk/dhdk_coauthorship_network.gml\")\n",
    "G2 = nx.read_gml(\"../../data/cs/cs_coauthorship_network.gml\")\n",
    "G3 = nx.read_gml(\"../../data/it/it_coauthorship_network.gml\")\n",
    "\n",
    "data = [\n",
    "    (\"DHDK\", G1.number_of_nodes(), G1.number_of_edges()),\n",
    "    (\"CS\", G2.number_of_nodes(), G2.number_of_edges()),\n",
    "    (\"IT\", G3.number_of_nodes(), G3.number_of_edges()),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Graph\", \"Number of Nodes\", \"Number of Edges\"])\n",
    "\n",
    "latex_table = df.to_latex(index=False, caption=\"Number of nodes and edges for each graph.\", label=\"tab:graph_stats\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>EigenvectorCentrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOMASI, FRANCESCA</td>\n",
       "      <td>DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA</td>\n",
       "      <td>0.198388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAQUINO, MARILENA</td>\n",
       "      <td>DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA</td>\n",
       "      <td>0.184361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PERONI, SILVIO</td>\n",
       "      <td>DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA</td>\n",
       "      <td>0.183052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BARZAGHI, SEBASTIAN</td>\n",
       "      <td>DIPARTIMENTO DI BENI CULTURALI</td>\n",
       "      <td>0.179906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VITTUARI, LUCA</td>\n",
       "      <td>DIPARTIMENTO DI INGEGNERIA CIVILE, CHIMICA, AMBIENTALE E DEI MATERIALI</td>\n",
       "      <td>0.177566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FERDANI, DANIELE</td>\n",
       "      <td>DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA</td>\n",
       "      <td>0.177566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COLLINA, FEDERICA</td>\n",
       "      <td>DIPARTIMENTO DI BENI CULTURALI</td>\n",
       "      <td>0.177566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FABBRI, FRANCESCA</td>\n",
       "      <td>DIPARTIMENTO DI BENI CULTURALI</td>\n",
       "      <td>0.177566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GIACOMINI, FEDERICA</td>\n",
       "      <td>None</td>\n",
       "      <td>0.177566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BORDIGNON, ALICE</td>\n",
       "      <td>DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA</td>\n",
       "      <td>0.177566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name  \\\n",
       "0    TOMASI, FRANCESCA   \n",
       "1    DAQUINO, MARILENA   \n",
       "2       PERONI, SILVIO   \n",
       "3  BARZAGHI, SEBASTIAN   \n",
       "4       VITTUARI, LUCA   \n",
       "5     FERDANI, DANIELE   \n",
       "6    COLLINA, FEDERICA   \n",
       "7    FABBRI, FRANCESCA   \n",
       "8  GIACOMINI, FEDERICA   \n",
       "9     BORDIGNON, ALICE   \n",
       "\n",
       "                                                              Affiliation  \\\n",
       "0                      DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA   \n",
       "1                      DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA   \n",
       "2                      DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA   \n",
       "3                                          DIPARTIMENTO DI BENI CULTURALI   \n",
       "4  DIPARTIMENTO DI INGEGNERIA CIVILE, CHIMICA, AMBIENTALE E DEI MATERIALI   \n",
       "5                      DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA   \n",
       "6                                          DIPARTIMENTO DI BENI CULTURALI   \n",
       "7                                          DIPARTIMENTO DI BENI CULTURALI   \n",
       "8                                                                    None   \n",
       "9                      DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA   \n",
       "\n",
       "   EigenvectorCentrality  \n",
       "0               0.198388  \n",
       "1               0.184361  \n",
       "2               0.183052  \n",
       "3               0.179906  \n",
       "4               0.177566  \n",
       "5               0.177566  \n",
       "6               0.177566  \n",
       "7               0.177566  \n",
       "8               0.177566  \n",
       "9               0.177566  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node_attributes = nx.get_node_attributes(G1, \"affiliation\")\n",
    "# df_dhdk = pd.DataFrame(G1, columns=[\"Name\"])\n",
    "# df_dhdk.rename(columns={'0': 'Name'}, inplace=True)\n",
    "# df_dhdk\n",
    "\n",
    "# degree_centrality = nx.degree_centrality(G1)\n",
    "# dc_data = pd.DataFrame({\"Name\": list(degree_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in degree_centrality.keys()],\n",
    "#                         \"DegreeCentrality\": list(degree_centrality.values())\n",
    "#                         }).sort_values(by=\"DegreeCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# dc_data.head(10)\n",
    "\n",
    "# weighted_betweenness_centrality = nx.betweenness_centrality(G1, weight=\"weight\")\n",
    "\n",
    "# wbc_data = pd.DataFrame({\"Name\": list(weighted_betweenness_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in weighted_betweenness_centrality.keys()],\n",
    "#                         \"WeightedBetweennessCentrality\": list(weighted_betweenness_centrality.values())\n",
    "#                         }).sort_values(by=\"WeightedBetweennessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# wbc_data.head(10)\n",
    "# betweenness_centrality = nx.betweenness_centrality(G1)\n",
    "\n",
    "# bc_data = pd.DataFrame({\"Name\": list(betweenness_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in betweenness_centrality.keys()],\n",
    "#                         \"BetweennessCentrality\": list(betweenness_centrality.values())\n",
    "#                         }).sort_values(by=\"BetweennessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# bc_data.head(10)\n",
    "\n",
    "# weighted_closeness_centrality = nx.closeness_centrality(G1, distance=\"weight\")\n",
    "\n",
    "# wcc_data = pd.DataFrame({\"Name\": list(weighted_closeness_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in weighted_closeness_centrality.keys()],\n",
    "#                         \"WeightedClosenessCentrality\": list(weighted_closeness_centrality.values())\n",
    "#                         }).sort_values(by=\"WeightedClosenessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# wcc_data.head(10)\n",
    "\n",
    "# closeness_centrality = nx.closeness_centrality(G1)\n",
    "\n",
    "# cc_data = pd.DataFrame({\"Name\": list(closeness_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in closeness_centrality.keys()],\n",
    "#                         \"ClosenessCentrality\": list(closeness_centrality.values())\n",
    "#                         }).sort_values(by=\"ClosenessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# cc_data.head(10)\n",
    "\n",
    "# weighted_eigenvector_centrality = nx.eigenvector_centrality(G1, weight=\"weight\")\n",
    "\n",
    "# wec_data = pd.DataFrame({\"Name\": list(weighted_eigenvector_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in weighted_eigenvector_centrality.keys()],\n",
    "#                         \"WeightedEigenvectorCentrality\": list(weighted_eigenvector_centrality.values())\n",
    "#                         }).sort_values(by=\"WeightedEigenvectorCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# wec_data.head(10)\n",
    "\n",
    "# eigenvector_centrality = nx.eigenvector_centrality(G1)\n",
    "\n",
    "# ec_data = pd.DataFrame({\"Name\": list(eigenvector_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in eigenvector_centrality.keys()],\n",
    "#                         \"EigenvectorCentrality\": list(eigenvector_centrality.values())\n",
    "#                         }).sort_values(by=\"EigenvectorCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# ec_data.head(10)\n",
    "\n",
    "node_attributes = nx.get_node_attributes(G3, \"affiliation\")\n",
    "# df_dhdk = pd.DataFrame(G1, columns=[\"Name\"])\n",
    "# df_cs = pd.DataFrame(G2, columns=[\"Name\"])\n",
    "df_it = pd.DataFrame(G3, columns=[\"Name\"])\n",
    "# df_dhdk.rename(columns={'0': 'Name'}, inplace=True)\n",
    "# df_dhdk\n",
    "\n",
    "degree_centrality = nx.degree_centrality(G3)\n",
    "dc_data = pd.DataFrame({\"Name\": list(degree_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in degree_centrality.keys()],\n",
    "                        \"DegreeCentrality\": list(degree_centrality.values())\n",
    "                        }).sort_values(by=\"DegreeCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "dc_data.head(10)\n",
    "\n",
    "weighted_betweenness_centrality = nx.betweenness_centrality(G3, weight=\"weight\")\n",
    "\n",
    "wbc_data = pd.DataFrame({\"Name\": list(weighted_betweenness_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in weighted_betweenness_centrality.keys()],\n",
    "                        \"WeightedBetweennessCentrality\": list(weighted_betweenness_centrality.values())\n",
    "                        }).sort_values(by=\"WeightedBetweennessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "wbc_data.head(10)\n",
    "betweenness_centrality = nx.betweenness_centrality(G3)\n",
    "\n",
    "bc_data = pd.DataFrame({\"Name\": list(betweenness_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in betweenness_centrality.keys()],\n",
    "                        \"BetweennessCentrality\": list(betweenness_centrality.values())\n",
    "                        }).sort_values(by=\"BetweennessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "bc_data.head(10)\n",
    "\n",
    "weighted_closeness_centrality = nx.closeness_centrality(G3, distance=\"weight\")\n",
    "\n",
    "wcc_data = pd.DataFrame({\"Name\": list(weighted_closeness_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in weighted_closeness_centrality.keys()],\n",
    "                        \"WeightedClosenessCentrality\": list(weighted_closeness_centrality.values())\n",
    "                        }).sort_values(by=\"WeightedClosenessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "wcc_data.head(10)\n",
    "\n",
    "closeness_centrality = nx.closeness_centrality(G3)\n",
    "\n",
    "cc_data = pd.DataFrame({\"Name\": list(closeness_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in closeness_centrality.keys()],\n",
    "                        \"ClosenessCentrality\": list(closeness_centrality.values())\n",
    "                        }).sort_values(by=\"ClosenessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "cc_data.head(10)\n",
    "\n",
    "weighted_eigenvector_centrality = nx.eigenvector_centrality(G3, weight=\"weight\")\n",
    "\n",
    "wec_data = pd.DataFrame({\"Name\": list(weighted_eigenvector_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in weighted_eigenvector_centrality.keys()],\n",
    "                        \"WeightedEigenvectorCentrality\": list(weighted_eigenvector_centrality.values())\n",
    "                        }).sort_values(by=\"WeightedEigenvectorCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "wec_data.head(10)\n",
    "\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G3)\n",
    "\n",
    "ec_data = pd.DataFrame({\"Name\": list(eigenvector_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in eigenvector_centrality.keys()],\n",
    "                        \"EigenvectorCentrality\": list(eigenvector_centrality.values())\n",
    "                        }).sort_values(by=\"EigenvectorCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "ec_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Centrality measures, weighted and not}\n",
      "\\label{tab:centrality_stats}\n",
      "\\begin{tabular}{lrrrrrll}\n",
      "\\toprule\n",
      "             Name &  DegreeCentrality &  WeightedBetweennessCentrality &  BetweennessCentrality &  WeightedClosenessCentrality &  ClosenessCentrality & WeightedEigenvectorCentrality & EigenvectorCentrality \\\\\n",
      "\\midrule\n",
      "TOMASI, FRANCESCA &          0.280528 &                       0.370793 &               0.490807 &                     0.180190 &             0.329182 &                  0.3389487662 &          0.1983876340 \\\\\n",
      " CHINES, LOREDANA &          0.148515 &                       0.042855 &               0.069310 &                     0.176548 &             0.305437 &                  0.0083982820 &          0.0124121059 \\\\\n",
      "DAQUINO, MARILENA &          0.135314 &                       0.009556 &               0.003716 &                     0.146399 &             0.259735 &                  0.0376362767 &          0.1843606746 \\\\\n",
      "     TINTI, PAOLO &          0.128713 &                       0.077326 &               0.113041 &                     0.151641 &             0.302135 &                  0.0055537653 &          0.0121696303 \\\\\n",
      "   PERONI, SILVIO &          0.128713 &                       0.019465 &               0.049502 &                     0.150094 &             0.269244 &                  0.0277595983 &          0.1830523643 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mguen\\AppData\\Local\\Temp\\ipykernel_8916\\3444003992.py:26: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_centrality_table = centrality_data_head.to_latex(index=False, caption=\"Centrality measures, weighted and not\", label=\"tab:centrality_stats\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_dhdk, dc_data, wbc_data, bc_data, wcc_data, cc_data, wec_data, ec_data are DataFrames with a common column \"Name\"\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "centrality_data = pd.concat([df_it.set_index(\"Name\"), dc_data.set_index(\"Name\"), wbc_data.set_index(\"Name\"), bc_data.set_index(\"Name\"), wcc_data.set_index(\"Name\"), cc_data.set_index(\"Name\"), wec_data.set_index(\"Name\"), ec_data.set_index(\"Name\")], axis=1)\n",
    "\n",
    "# Specify the selected columns\n",
    "selected_columns = [\"DegreeCentrality\", \"WeightedBetweennessCentrality\", \"BetweennessCentrality\", \"WeightedClosenessCentrality\", \"ClosenessCentrality\", \"WeightedEigenvectorCentrality\", \"EigenvectorCentrality\"]\n",
    "\n",
    "# Keep only the selected columns\n",
    "centrality_data = centrality_data[selected_columns]\n",
    "\n",
    "# Reset the index to include \"Name\" as a column\n",
    "centrality_data.reset_index(inplace=True)\n",
    "\n",
    "# Format Eigenvector values without scientific notation\n",
    "centrality_data['WeightedEigenvectorCentrality'] = centrality_data['WeightedEigenvectorCentrality'].apply(lambda x: '{:.10f}'.format(x))\n",
    "centrality_data['EigenvectorCentrality'] = centrality_data['EigenvectorCentrality'].apply(lambda x: '{:.10f}'.format(x))\n",
    "\n",
    "# Sort the DataFrame by 'DegreeCentrality' in ascending order\n",
    "centrality_data = centrality_data.sort_values(by='DegreeCentrality', ascending=False)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "centrality_data_head = centrality_data.head()\n",
    "latex_centrality_table = centrality_data_head.to_latex(index=False, caption=\"Centrality measures, weighted and not\", label=\"tab:centrality_stats\")\n",
    "print(latex_centrality_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Clustering measure, KCore and Community detection}\n",
      "\\label{tab:other_stats}\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "           index &  WeightedClustering &  Clustering &  KCore &  Community \\\\\n",
      "\\midrule\n",
      "CITTI, FRANCESCO &            0.261208 &        0.85 &     12 &          6 \\\\\n",
      "  PASETTI, LUCIA &            0.260227 &        0.85 &     12 &          6 \\\\\n",
      "  ZIOSI, ANTONIO &            0.260227 &        0.85 &     12 &          6 \\\\\n",
      "   NERI, CAMILLO &            0.260227 &        0.85 &     12 &          6 \\\\\n",
      "    PIERI, BRUNA &            0.260227 &        0.85 &     12 &          6 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mguen\\AppData\\Local\\Temp\\ipykernel_8916\\3249603171.py:83: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_clkc_table = clkc_data_head.to_latex(index=False, caption=\"Clustering measure, KCore and Community detection\", label=\"tab:other_stats\")\n"
     ]
    }
   ],
   "source": [
    "# weighted_clustering = nx.clustering(G1, weight=\"weight\")\n",
    "# weighted_clustering_data = pd.DataFrame({\n",
    "#     \"Name\": list(weighted_clustering.keys()),\n",
    "#     \"Affiliation\": [node_attributes[node] for node in weighted_clustering.keys()],\n",
    "#     \"WeightedClustering\": list(weighted_clustering.values())\n",
    "# }).sort_values(by=\"WeightedClustering\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# clustering = nx.clustering(G1)\n",
    "# clustering_data = pd.DataFrame({\n",
    "#     \"Name\": list(clustering.keys()),\n",
    "#     \"Affiliation\": [node_attributes[node] for node in clustering.keys()],\n",
    "#     \"Clustering\": list(clustering.values())\n",
    "# }).sort_values(by=\"Clustering\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# core_number = nx.core_number(G1)\n",
    "# k_data = pd.DataFrame({\n",
    "#     \"Name\": list(core_number.keys()),\n",
    "#     \"Affiliation\": [node_attributes[node] for node in core_number.keys()],\n",
    "#     \"KCore\": list(core_number.values())\n",
    "# }).sort_values(by=\"KCore\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# communities = nx.algorithms.community.greedy_modularity_communities(G1)\n",
    "# community_mapping = {}\n",
    "# for i, community in enumerate(communities):\n",
    "#     for node in community:\n",
    "#         community_mapping[node] = i\n",
    "\n",
    "# c_data = pd.DataFrame.from_dict(community_mapping, orient=\"index\", columns=[\"Community\"]).reset_index()\n",
    "\n",
    "# # Concatenate and reset index\n",
    "# clkc_data = pd.concat([df_dhdk.set_index(\"Name\"), weighted_clustering_data.set_index(\"Name\"), clustering_data.set_index(\"Name\"), k_data.set_index(\"Name\"), c_data.set_index(\"index\")], axis=1).reset_index()\n",
    "\n",
    "# # Drop the \"Affiliation\" column\n",
    "# clkc_data = clkc_data.drop(\"Affiliation\", axis=1)\n",
    "# clkc_data = clkc_data.sort_values(by='KCore', ascending=False)\n",
    "\n",
    "\n",
    "# clkc_data_head = clkc_data.head()\n",
    "# clkc_data_head\n",
    "# latex_clkc_table = clkc_data_head.to_latex(index=False, caption=\"Clustering measure, KCore and Community detection\", label=\"tab:other_stats\")\n",
    "# print(latex_clkc_table)\n",
    "\n",
    "\n",
    "weighted_clustering = nx.clustering(G3, weight=\"weight\")\n",
    "weighted_clustering_data = pd.DataFrame({\n",
    "    \"Name\": list(weighted_clustering.keys()),\n",
    "    \"Affiliation\": [node_attributes[node] for node in weighted_clustering.keys()],\n",
    "    \"WeightedClustering\": list(weighted_clustering.values())\n",
    "}).sort_values(by=\"WeightedClustering\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "clustering = nx.clustering(G3)\n",
    "clustering_data = pd.DataFrame({\n",
    "    \"Name\": list(clustering.keys()),\n",
    "    \"Affiliation\": [node_attributes[node] for node in clustering.keys()],\n",
    "    \"Clustering\": list(clustering.values())\n",
    "}).sort_values(by=\"Clustering\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "core_number = nx.core_number(G3)\n",
    "k_data = pd.DataFrame({\n",
    "    \"Name\": list(core_number.keys()),\n",
    "    \"Affiliation\": [node_attributes[node] for node in core_number.keys()],\n",
    "    \"KCore\": list(core_number.values())\n",
    "}).sort_values(by=\"KCore\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "communities = nx.algorithms.community.greedy_modularity_communities(G3)\n",
    "community_mapping = {}\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        community_mapping[node] = i\n",
    "\n",
    "c_data = pd.DataFrame.from_dict(community_mapping, orient=\"index\", columns=[\"Community\"]).reset_index()\n",
    "\n",
    "# Concatenate and reset index\n",
    "clkc_data = pd.concat([df_it.set_index(\"Name\"), weighted_clustering_data.set_index(\"Name\"), clustering_data.set_index(\"Name\"), k_data.set_index(\"Name\"), c_data.set_index(\"index\")], axis=1).reset_index()\n",
    "\n",
    "# Drop the \"Affiliation\" column\n",
    "clkc_data = clkc_data.drop(\"Affiliation\", axis=1)\n",
    "clkc_data = clkc_data.sort_values(by='WeightedClustering', ascending=False)\n",
    "\n",
    "\n",
    "clkc_data_head = clkc_data.head()\n",
    "clkc_data_head\n",
    "latex_clkc_table = clkc_data_head.to_latex(index=False, caption=\"Clustering measure, KCore and Community detection\", label=\"tab:other_stats\")\n",
    "print(latex_clkc_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

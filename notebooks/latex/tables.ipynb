{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import log\n",
    "import statistics as st\n",
    "# from lattice_reference import *\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    " \n",
    "threads = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Number of nodes and edges for each graph.}\n",
      "\\label{tab:graph_stats}\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "Graph &  Number of Nodes &  Number of Edges \\\\\n",
      "\\midrule\n",
      " DHDK &              398 &             1889 \\\\\n",
      "   CS &              493 &             1999 \\\\\n",
      "   IT &              304 &             1523 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mguen\\AppData\\Local\\Temp\\ipykernel_9072\\565526070.py:13: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df.to_latex(index=False, caption=\"Number of nodes and edges for each graph.\", label=\"tab:graph_stats\")\n"
     ]
    }
   ],
   "source": [
    "G1 = nx.read_gml(\"../../data/dhdk/dhdk_coauthorship_network.gml\")\n",
    "G2 = nx.read_gml(\"../../data/cs/cs_coauthorship_network.gml\")\n",
    "G3 = nx.read_gml(\"../../data/it/it_coauthorship_network.gml\")\n",
    "\n",
    "data = [\n",
    "    (\"DHDK\", G1.number_of_nodes(), G1.number_of_edges()),\n",
    "    (\"CS\", G2.number_of_nodes(), G2.number_of_edges()),\n",
    "    (\"IT\", G3.number_of_nodes(), G3.number_of_edges()),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Graph\", \"Number of Nodes\", \"Number of Edges\"])\n",
    "\n",
    "latex_table = df.to_latex(index=False, caption=\"Number of nodes and edges for each graph.\", label=\"tab:graph_stats\")\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>EigenvectorCentrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOMASI, FRANCESCA</td>\n",
       "      <td>DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA</td>\n",
       "      <td>0.197797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERONI, SILVIO</td>\n",
       "      <td>DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA</td>\n",
       "      <td>0.197098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAQUINO, MARILENA</td>\n",
       "      <td>DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA</td>\n",
       "      <td>0.186873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BARZAGHI, SEBASTIAN</td>\n",
       "      <td>DIPARTIMENTO DI BENI CULTURALI</td>\n",
       "      <td>0.179284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PESCARIN, SOFIA</td>\n",
       "      <td>ARAG - AREA FINANZA E PARTECIPATE</td>\n",
       "      <td>0.178458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MASSARI, ARCANGELO</td>\n",
       "      <td>DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA</td>\n",
       "      <td>0.177865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HEIBI, IVAN</td>\n",
       "      <td>DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA</td>\n",
       "      <td>0.177633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MORETTI, ARIANNA</td>\n",
       "      <td>Alma Mater Studiorum  Universita' di Bologna</td>\n",
       "      <td>0.177052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RENDA, GIULIA</td>\n",
       "      <td>Alma Mater Studiorum  Universita' di Bologna</td>\n",
       "      <td>0.176759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IANNUCCI, ALESSANDRO</td>\n",
       "      <td>DIPARTIMENTO DI BENI CULTURALI</td>\n",
       "      <td>0.175661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name                                         Affiliation  \\\n",
       "0     TOMASI, FRANCESCA  DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA   \n",
       "1        PERONI, SILVIO  DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA   \n",
       "2     DAQUINO, MARILENA  DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA   \n",
       "3   BARZAGHI, SEBASTIAN                      DIPARTIMENTO DI BENI CULTURALI   \n",
       "4       PESCARIN, SOFIA                   ARAG - AREA FINANZA E PARTECIPATE   \n",
       "5    MASSARI, ARCANGELO  DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA   \n",
       "6           HEIBI, IVAN  DIPARTIMENTO DI FILOLOGIA CLASSICA E ITALIANISTICA   \n",
       "7      MORETTI, ARIANNA        Alma Mater Studiorum  Universita' di Bologna   \n",
       "8         RENDA, GIULIA        Alma Mater Studiorum  Universita' di Bologna   \n",
       "9  IANNUCCI, ALESSANDRO                      DIPARTIMENTO DI BENI CULTURALI   \n",
       "\n",
       "   EigenvectorCentrality  \n",
       "0               0.197797  \n",
       "1               0.197098  \n",
       "2               0.186873  \n",
       "3               0.179284  \n",
       "4               0.178458  \n",
       "5               0.177865  \n",
       "6               0.177633  \n",
       "7               0.177052  \n",
       "8               0.176759  \n",
       "9               0.175661  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node_attributes = nx.get_node_attributes(G1, \"affiliation\")\n",
    "# df_dhdk = pd.DataFrame(G1, columns=[\"Name\"])\n",
    "# df_dhdk.rename(columns={'0': 'Name'}, inplace=True)\n",
    "# df_dhdk\n",
    "\n",
    "# degree_centrality = nx.degree_centrality(G1)\n",
    "# dc_data = pd.DataFrame({\"Name\": list(degree_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in degree_centrality.keys()],\n",
    "#                         \"DegreeCentrality\": list(degree_centrality.values())\n",
    "#                         }).sort_values(by=\"DegreeCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# dc_data.head(10)\n",
    "\n",
    "# weighted_betweenness_centrality = nx.betweenness_centrality(G1, weight=\"weight\")\n",
    "\n",
    "# wbc_data = pd.DataFrame({\"Name\": list(weighted_betweenness_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in weighted_betweenness_centrality.keys()],\n",
    "#                         \"WeightedBetweennessCentrality\": list(weighted_betweenness_centrality.values())\n",
    "#                         }).sort_values(by=\"WeightedBetweennessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# wbc_data.head(10)\n",
    "# betweenness_centrality = nx.betweenness_centrality(G1)\n",
    "\n",
    "# bc_data = pd.DataFrame({\"Name\": list(betweenness_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in betweenness_centrality.keys()],\n",
    "#                         \"BetweennessCentrality\": list(betweenness_centrality.values())\n",
    "#                         }).sort_values(by=\"BetweennessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# bc_data.head(10)\n",
    "\n",
    "# weighted_closeness_centrality = nx.closeness_centrality(G1, distance=\"weight\")\n",
    "\n",
    "# wcc_data = pd.DataFrame({\"Name\": list(weighted_closeness_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in weighted_closeness_centrality.keys()],\n",
    "#                         \"WeightedClosenessCentrality\": list(weighted_closeness_centrality.values())\n",
    "#                         }).sort_values(by=\"WeightedClosenessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# wcc_data.head(10)\n",
    "\n",
    "# closeness_centrality = nx.closeness_centrality(G1)\n",
    "\n",
    "# cc_data = pd.DataFrame({\"Name\": list(closeness_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in closeness_centrality.keys()],\n",
    "#                         \"ClosenessCentrality\": list(closeness_centrality.values())\n",
    "#                         }).sort_values(by=\"ClosenessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# cc_data.head(10)\n",
    "\n",
    "# weighted_eigenvector_centrality = nx.eigenvector_centrality(G1, weight=\"weight\")\n",
    "\n",
    "# wec_data = pd.DataFrame({\"Name\": list(weighted_eigenvector_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in weighted_eigenvector_centrality.keys()],\n",
    "#                         \"WeightedEigenvectorCentrality\": list(weighted_eigenvector_centrality.values())\n",
    "#                         }).sort_values(by=\"WeightedEigenvectorCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# wec_data.head(10)\n",
    "\n",
    "# eigenvector_centrality = nx.eigenvector_centrality(G1)\n",
    "\n",
    "# ec_data = pd.DataFrame({\"Name\": list(eigenvector_centrality.keys()),\n",
    "#                         \"Affiliation\": [node_attributes[node] for node in eigenvector_centrality.keys()],\n",
    "#                         \"EigenvectorCentrality\": list(eigenvector_centrality.values())\n",
    "#                         }).sort_values(by=\"EigenvectorCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# ec_data.head(10)\n",
    "\n",
    "node_attributes = nx.get_node_attributes(G1, \"affiliation\")\n",
    "df_dhdk = pd.DataFrame(G1, columns=[\"Name\"])\n",
    "# df_cs = pd.DataFrame(G2, columns=[\"Name\"])\n",
    "# df_it = pd.DataFrame(G3, columns=[\"Name\"])\n",
    "df_dhdk.rename(columns={'0': 'Name'}, inplace=True)\n",
    "df_dhdk\n",
    "\n",
    "degree_centrality = nx.degree_centrality(G1)\n",
    "dc_data = pd.DataFrame({\"Name\": list(degree_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in degree_centrality.keys()],\n",
    "                        \"DegreeCentrality\": list(degree_centrality.values())\n",
    "                        }).sort_values(by=\"DegreeCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "dc_data.head(10)\n",
    "\n",
    "weighted_betweenness_centrality = nx.betweenness_centrality(G1, weight=\"weight\")\n",
    "\n",
    "wbc_data = pd.DataFrame({\"Name\": list(weighted_betweenness_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in weighted_betweenness_centrality.keys()],\n",
    "                        \"WeightedBetweennessCentrality\": list(weighted_betweenness_centrality.values())\n",
    "                        }).sort_values(by=\"WeightedBetweennessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "wbc_data.head(10)\n",
    "betweenness_centrality = nx.betweenness_centrality(G1)\n",
    "\n",
    "bc_data = pd.DataFrame({\"Name\": list(betweenness_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in betweenness_centrality.keys()],\n",
    "                        \"BetweennessCentrality\": list(betweenness_centrality.values())\n",
    "                        }).sort_values(by=\"BetweennessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "bc_data.head(10)\n",
    "\n",
    "weighted_closeness_centrality = nx.closeness_centrality(G1, distance=\"weight\")\n",
    "\n",
    "wcc_data = pd.DataFrame({\"Name\": list(weighted_closeness_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in weighted_closeness_centrality.keys()],\n",
    "                        \"WeightedClosenessCentrality\": list(weighted_closeness_centrality.values())\n",
    "                        }).sort_values(by=\"WeightedClosenessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "wcc_data.head(10)\n",
    "\n",
    "closeness_centrality = nx.closeness_centrality(G1)\n",
    "\n",
    "cc_data = pd.DataFrame({\"Name\": list(closeness_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in closeness_centrality.keys()],\n",
    "                        \"ClosenessCentrality\": list(closeness_centrality.values())\n",
    "                        }).sort_values(by=\"ClosenessCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "cc_data.head(10)\n",
    "\n",
    "weighted_eigenvector_centrality = nx.eigenvector_centrality(G1, weight=\"weight\")\n",
    "\n",
    "wec_data = pd.DataFrame({\"Name\": list(weighted_eigenvector_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in weighted_eigenvector_centrality.keys()],\n",
    "                        \"WeightedEigenvectorCentrality\": list(weighted_eigenvector_centrality.values())\n",
    "                        }).sort_values(by=\"WeightedEigenvectorCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "wec_data.head(10)\n",
    "\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G1)\n",
    "\n",
    "ec_data = pd.DataFrame({\"Name\": list(eigenvector_centrality.keys()),\n",
    "                        \"Affiliation\": [node_attributes[node] for node in eigenvector_centrality.keys()],\n",
    "                        \"EigenvectorCentrality\": list(eigenvector_centrality.values())\n",
    "                        }).sort_values(by=\"EigenvectorCentrality\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "ec_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Centrality measures, weighted and not}\n",
      "\\label{tab:centrality_stats}\n",
      "\\begin{tabular}{lrrrrrll}\n",
      "\\toprule\n",
      "             Name &  DegreeCentrality &  WeightedBetweennessCentrality &  BetweennessCentrality &  WeightedClosenessCentrality &  ClosenessCentrality & WeightedEigenvectorCentrality & EigenvectorCentrality \\\\\n",
      "\\midrule\n",
      "TOMASI, FRANCESCA &          0.214106 &                       0.365687 &               0.383470 &                     0.184239 &             0.420055 &                  0.2799114296 &          0.1977971700 \\\\\n",
      "   PERONI, SILVIO &          0.188917 &                       0.097948 &               0.185211 &                     0.150193 &             0.394565 &                  0.5393761733 &          0.1970975680 \\\\\n",
      "  MILANO, MICHELA &          0.166247 &                       0.157211 &               0.170525 &                     0.128068 &             0.278413 &                  0.0000187225 &          0.0010553084 \\\\\n",
      "    VITALI, FABIO &          0.138539 &                       0.105919 &               0.149762 &                     0.146802 &             0.380147 &                  0.5310574724 &          0.0394540152 \\\\\n",
      "BARTOLINI, ILARIA &          0.123426 &                       0.310429 &               0.310492 &                     0.160134 &             0.355063 &                  0.0021118391 &          0.0087218548 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mguen\\AppData\\Local\\Temp\\ipykernel_9072\\3992640656.py:26: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_centrality_table = centrality_data_head.to_latex(index=False, caption=\"Centrality measures, weighted and not\", label=\"tab:centrality_stats\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_dhdk, dc_data, wbc_data, bc_data, wcc_data, cc_data, wec_data, ec_data are DataFrames with a common column \"Name\"\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "centrality_data = pd.concat([df_dhdk.set_index(\"Name\"), dc_data.set_index(\"Name\"), wbc_data.set_index(\"Name\"), bc_data.set_index(\"Name\"), wcc_data.set_index(\"Name\"), cc_data.set_index(\"Name\"), wec_data.set_index(\"Name\"), ec_data.set_index(\"Name\")], axis=1)\n",
    "\n",
    "# Specify the selected columns\n",
    "selected_columns = [\"DegreeCentrality\", \"WeightedBetweennessCentrality\", \"BetweennessCentrality\", \"WeightedClosenessCentrality\", \"ClosenessCentrality\", \"WeightedEigenvectorCentrality\", \"EigenvectorCentrality\"]\n",
    "\n",
    "# Keep only the selected columns\n",
    "centrality_data = centrality_data[selected_columns]\n",
    "\n",
    "# Reset the index to include \"Name\" as a column\n",
    "centrality_data.reset_index(inplace=True)\n",
    "\n",
    "# Format Eigenvector values without scientific notation\n",
    "centrality_data['WeightedEigenvectorCentrality'] = centrality_data['WeightedEigenvectorCentrality'].apply(lambda x: '{:.10f}'.format(x))\n",
    "centrality_data['EigenvectorCentrality'] = centrality_data['EigenvectorCentrality'].apply(lambda x: '{:.10f}'.format(x))\n",
    "\n",
    "# Sort the DataFrame by 'DegreeCentrality' in ascending order\n",
    "centrality_data = centrality_data.sort_values(by='DegreeCentrality', ascending=False)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "centrality_data_head = centrality_data.head()\n",
    "latex_centrality_table = centrality_data_head.to_latex(index=False, caption=\"Centrality measures, weighted and not\", label=\"tab:centrality_stats\")\n",
    "print(latex_centrality_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Clustering measure, KCore and Community detection}\n",
      "\\label{tab:other_stats}\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "                 index &  WeightedClustering &  Clustering &  KCore &  Community &  WeightedCommunity \\\\\n",
      "\\midrule\n",
      "        MONTALI, MARCO &            0.108872 &         1.0 &      4 &          7 &                  6 \\\\\n",
      "       LUCCHI, ROBERTO &            0.091796 &         1.0 &      5 &          0 &                  1 \\\\\n",
      "MONTECCHIARI, LEONARDO &            0.071099 &         1.0 &      3 &          2 &                  2 \\\\\n",
      "      BRACUTO, MICHELE &            0.064661 &         1.0 &      3 &          2 &                  3 \\\\\n",
      "        ROUHI, RAHIMEH &            0.064291 &         1.0 &      2 &          5 &                  8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mguen\\AppData\\Local\\Temp\\ipykernel_9072\\1255540490.py:91: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_clkc_table = clkc_data_head.to_latex(index=False, caption=\"Clustering measure, KCore and Community detection\", label=\"tab:other_stats\")\n"
     ]
    }
   ],
   "source": [
    "# weighted_clustering = nx.clustering(G1, weight=\"weight\")\n",
    "# weighted_clustering_data = pd.DataFrame({\n",
    "#     \"Name\": list(weighted_clustering.keys()),\n",
    "#     \"Affiliation\": [node_attributes[node] for node in weighted_clustering.keys()],\n",
    "#     \"WeightedClustering\": list(weighted_clustering.values())\n",
    "# }).sort_values(by=\"WeightedClustering\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# clustering = nx.clustering(G1)\n",
    "# clustering_data = pd.DataFrame({\n",
    "#     \"Name\": list(clustering.keys()),\n",
    "#     \"Affiliation\": [node_attributes[node] for node in clustering.keys()],\n",
    "#     \"Clustering\": list(clustering.values())\n",
    "# }).sort_values(by=\"Clustering\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# core_number = nx.core_number(G1)\n",
    "# k_data = pd.DataFrame({\n",
    "#     \"Name\": list(core_number.keys()),\n",
    "#     \"Affiliation\": [node_attributes[node] for node in core_number.keys()],\n",
    "#     \"KCore\": list(core_number.values())\n",
    "# }).sort_values(by=\"KCore\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# communities = nx.algorithms.community.greedy_modularity_communities(G1)\n",
    "# community_mapping = {}\n",
    "# for i, community in enumerate(communities):\n",
    "#     for node in community:\n",
    "#         community_mapping[node] = i\n",
    "\n",
    "# c_data = pd.DataFrame.from_dict(community_mapping, orient=\"index\", columns=[\"Community\"]).reset_index()\n",
    "\n",
    "# # Concatenate and reset index\n",
    "# clkc_data = pd.concat([df_dhdk.set_index(\"Name\"), weighted_clustering_data.set_index(\"Name\"), clustering_data.set_index(\"Name\"), k_data.set_index(\"Name\"), c_data.set_index(\"index\")], axis=1).reset_index()\n",
    "\n",
    "# # Drop the \"Affiliation\" column\n",
    "# clkc_data = clkc_data.drop(\"Affiliation\", axis=1)\n",
    "# clkc_data = clkc_data.sort_values(by='KCore', ascending=False)\n",
    "\n",
    "\n",
    "# clkc_data_head = clkc_data.head()\n",
    "# clkc_data_head\n",
    "# latex_clkc_table = clkc_data_head.to_latex(index=False, caption=\"Clustering measure, KCore and Community detection\", label=\"tab:other_stats\")\n",
    "# print(latex_clkc_table)\n",
    "\n",
    "\n",
    "weighted_clustering = nx.clustering(G2, weight=\"weight\")\n",
    "weighted_clustering_data = pd.DataFrame({\n",
    "    \"Name\": list(weighted_clustering.keys()),\n",
    "    \"Affiliation\": [node_attributes[node] for node in weighted_clustering.keys()],\n",
    "    \"WeightedClustering\": list(weighted_clustering.values())\n",
    "}).sort_values(by=\"WeightedClustering\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "clustering = nx.clustering(G2)\n",
    "clustering_data = pd.DataFrame({\n",
    "    \"Name\": list(clustering.keys()),\n",
    "    \"Affiliation\": [node_attributes[node] for node in clustering.keys()],\n",
    "    \"Clustering\": list(clustering.values())\n",
    "}).sort_values(by=\"Clustering\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "core_number = nx.core_number(G2)\n",
    "k_data = pd.DataFrame({\n",
    "    \"Name\": list(core_number.keys()),\n",
    "    \"Affiliation\": [node_attributes[node] for node in core_number.keys()],\n",
    "    \"KCore\": list(core_number.values())\n",
    "}).sort_values(by=\"KCore\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "communities = nx.algorithms.community.greedy_modularity_communities(G2)\n",
    "community_mapping = {}\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        community_mapping[node] = i\n",
    "\n",
    "c_data = pd.DataFrame.from_dict(community_mapping, orient=\"index\", columns=[\"Community\"]).reset_index()\n",
    "\n",
    "weigthed_communities = nx.algorithms.community.greedy_modularity_communities(G2, weight=\"weight\")\n",
    "wcommunity_mapping = {}\n",
    "for i, wcommunity in enumerate(weigthed_communities):\n",
    "    for node in wcommunity:\n",
    "        wcommunity_mapping[node] = i\n",
    "\n",
    "wc_data = pd.DataFrame.from_dict(wcommunity_mapping, orient=\"index\", columns=[\"WeightedCommunity\"]).reset_index()\n",
    "\n",
    "# Concatenate and reset index\n",
    "clkc_data = pd.concat([df_cs.set_index(\"Name\"), weighted_clustering_data.set_index(\"Name\"), clustering_data.set_index(\"Name\"), k_data.set_index(\"Name\"), c_data.set_index(\"index\"), wc_data.set_index(\"index\")], axis=1).reset_index()\n",
    "\n",
    "# Drop the \"Affiliation\" column\n",
    "clkc_data = clkc_data.drop(\"Affiliation\", axis=1)\n",
    "clkc_data = clkc_data.sort_values(by='WeightedClustering', ascending=False)\n",
    "\n",
    "\n",
    "clkc_data_head = clkc_data.head()\n",
    "clkc_data_head\n",
    "latex_clkc_table = clkc_data_head.to_latex(index=False, caption=\"Clustering measure, KCore and Community detection\", label=\"tab:other_stats\")\n",
    "print(latex_clkc_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
